\documentclass{article}
%\usepackage[margin=1in]{geometry}   % set up margins
\usepackage[vmargin=1in,hmargin=1in]{geometry}
\usepackage{tikz}
\usepackage{booktabs}

\usepackage[backend=bibtex]{biblatex}


\thispagestyle{empty}
\begin{center}
\begin{minipage}{1.2\linewidth}
    \centering
 %   \rule{0.4\linewidth}{0.15\linewidth}\par
    \vspace{3cm}
%Thesis title
    \textbf{{\uppercase{\Large German Credit Data Scoring using R\par}}}
    \vspace{2cm}
    %Degree
    {\Large Business Data Analytics Project Report\par}
    \vspace{2cm}
    %University logo
   \hspace{1.5cm} \includegraphics[width=0.35\linewidth]{hyderabad-university-publishes-mtech.jpg}\newline
    
    {\textit{\hspace{0.5cm}Submitted by} \par}
%Author's name
  \centering
    {\Large Laltendu Das [15MCMI22]\par}
    {\Large Uma Revathi [15MCMI22]\par}
    {\Large  Rosni K V [15MCMI15]\par}
    \vspace{1cm}
    
    %Author's name
    {\textit{\hspace{1cm}Under the Guidance of} \par}
    {\Large Dr. V.Ravi, Associate Professor, IDRBT \par}
    \vspace{2cm}
    \centering
%Date
    {\textbf{\Large November 2015}}
\end{minipage}
\end{center}
\clearpage


\newpage
\renewcommand{\contentsname}{\centering Table of Contents}
\newline
\newline
\tableofcontents
\newpage
%\renewcommand{\listfigurename}{\centering List of Figures}
\listoffigures
%\renewcommand{\listoftables}{\centering List of Tables}
\listoftables
\newpage



\begin{document}

<<include=FALSE>>=
library(knitr)
opts_chunk$set(
concordance=TRUE
)
@


%\title {An Attractive Template of a Reproducible Data Analysis Document for an Awesome Class Project}
%\author{Mahbubul Majumder, PhD\\ Department of Mathematics\\ University of Nebraska at Omaha }

%\maketitle

<<echo=FALSE, eval=FALSE>>=
# This chunk is to solve the problem of bibitem
setwd("root/BDA_project/Report/")
Sys.setenv(TEXINPUTS=getwd(),
           BIBINPUTS=getwd(),
           BSTINPUTS=getwd())
@

\section{Abstract}
\hspace{0.5cm} Credit scoring uses quantitative measures of the performance and characteristics of past loans to predict the future performance of loans with similar characteristics.The objective of credit scoring is to help credit providers quantify and manage the financial risk involved in providing credit so that they can make better lending decisions quickly and more objectively. As a result, various kinds of credit scoring models are established to evaluate the customers' credit rank.
\par A credit scoring system should be able to classify customers as good credit those  who are expected to repay on time and as bad credit those who are expected to fail. A major problem for banks is how to determine the bad credit, because bad credit may cause serious problems in the future. This leads to loss in bank capital, lower bank revenues and subsequently increases bank losses, which can lead to insolvency or bankruptcy. The categorisation of good and bad credit is of fundamental importance, and is indeed the objective of a credit scoring model. Classification models for credit scoring are used to categorize new applicants as either accepted or rejected with respect to these characteristics. In some cases the final selection of the characteristics was based on the statistical analysis used, i.e. logistic regression, neural network etc.
\par This study illustrates the use of data mining techniques to construct credit scoring models. Also, it illustrates the comparison of credit scoring models to give a superior final model. The report also highlights each data mining approach using R language.\\
%\end{abstract}
%\tableofcontents

\section{Introduction} 
\hspace{0.5cm} Credit scoring is one of the applications for predictive modeling, to predict whether or not credit extended to an applicant will likely result in profit or losses for the lending institution. For instance when a bank provides money to an individual, and expects to be paid back in time with interest commensurate with the risk of default. When a bank grants loan to a new customer, bank uses techniques on the large sample of previous customers with their application details and subsequent credit history available. Applying techniques results in connection between the characteristics of the customers.
\par Banks use credit risk modeling in order to measure the amount of credit risk which they are exposed to. The most commonly used technique for this purpose is logistic regression. In our study, we applied different techniques like support vector machines, nearest neighbor, decision trees on data to classify the borrowers as good or bad. So that the borrowers which are classified as bad are not granted any credit.
\par For the experiments, we used the German credit data set which was available in the UCI Repository. The data set consists of 20 attributes (7 numerical and 13 categorical) and there are totally 1000 instances (300 bad and 700 good cases). It was produced by Strathclyde University and is associated with several academic work.
\par The models were compared based on their accuracy on the German credit data set by using 10-fold cross validation. We divided the data set into ten partitions. Then, we iteratively took one of the ten partitions as the test set and the combination of the other nine were used to form a training set. The accuracy of a hold-out partition was defined as the number of correct classifications over the total number of instances in the partition. Accuracy of the 10-fold cross validation procedure was calculated by dividing the sum of the accuracies of all hold-out partitions by ten.\\
%The first sentence of this section is so attractive that it made the reader concentrate on reading. The second sentence is so great that it made the reader forget the date. Rest of the sentences are so nice that at the end of the paragraph the reader can't just wait to see what is coming on the next paragraph. At this point reader does not mind if it gets a little technical.  \\
%
%The first sentence of any paragraph presents a clear message. The rest of the sentences just describe that idea and establish the facts so that the reader see the logical conclusion of the paragraph. The last sentence of the paragraph connects the following paragraphs or section.  \\
%
%Add some motivational pictures in this section whenever possible. This will provide the reader some relief from reading text after text. For example Figure \ref{fig:nice-plot} indeed make us happy that we have something else to concentrate. This motivational picture does not need to be generated from the data you are going to analyze. Notice that we added the \textbf{R} codes of generating the Figure~\ref{fig:nice-plot}.
%
%If we don't want to display the R codes, we just put option \texttt{echo=FALSE} in the head of the chunk. To add caption for the figure we write the caption in \texttt{fig.cap=`my figure captions'}.
%
%%%%%%<<nice-plot, fig.cap="My awesome figure caption really describes what this figure is about and what we see in this figure. Also notice that the figure size is kept in such a way that it fits in the text nicely - not too big nor too small", fig.width=4, fig.height=4, fig.align='center',fig.pos="hbtp",out.width='.45\\linewidth'>>=
%plot(women)
%@

%Also please don't forget to explain in details about what this figure is telling. It is really a bad idea not to say anything about the figure when you added it. Its like a product you are selling to someone who don't want to buy it. So, you have to be very serious about selling it with convincing argument.

%\subsection{Preparing this document} 
%This whole document is prepared using \textbf{R}  \cite{R-base} package \texttt{knitr} \cite{R-knitr}. It is a dynamic document and reproducible any number of times for any data sets. To start our work conveniently we need to install \textbf{R}, \texttt{RStudio} and \LaTeX{} \cite{lamport94} . Once our installation is done we will configure \texttt{RStudio} to work with \texttt{knitr}. For this first install \texttt{knitr} using command \texttt{install.packages("knitr")} and include the \texttt{knitr} library by command \texttt{library(knitr)}. Once \texttt{knitr} is installed go to the \texttt{RStudio} menu \texttt{Tools > Global Options...Sweave} and change `Weave Rnw files using' to indicate \texttt{Knitr}.\\

%Now we are ready to create our first document using \texttt{knitr}. Go to \texttt{File > New File > R Sweave} and it will start with a new template for a document. If you save this minimal template it will be saved as a \texttt{.Rnw} file. Now we can just start filling the template with our texts. To create a human readable pdf file from \texttt{.Rnw} we just click on \texttt{Compile PDF} in \texttt{RStudio} toolbar. \\

%{\bf PDF latex failure:} If you encounter any problem such as \texttt{Running pdflatex on ...failed} it could be due to the bibliography. To solve that problem what you can do is: Go back to the folder where you saved your \texttt{.Rnw} file and find the \texttt{.tex} file that is created automatically. Now run the \texttt{.tex} file from \LaTeX{} editor to create the pdf. Once you do this multiple times your bibliographies would be updated and you will be ready to work from \texttt{RStudio} as long as you don't change any object that has references in the file. There may be a better solution for this, but so far this worked for me. \\

%The solution for this problem: just add \texttt{\textbackslash usepackage[backend=bibtex]{biblatex}} in your preamble of the \texttt{.Rnw} file.

\section{Problem definition}\hspace{0.5cm}To develop a credit scoring model to predict the credit risk of applicants as bad risk(default) and good risk, which will help credit providers decide whether to grant loan to customers or not. The associated task for this problem is classification, and the German Credit Data set(source::UCI Machine Learning Repository) is using.

\section{About the data} \hspace{0.5cm} To meet with the objective of the analysis, ie, from credit providers perspective, to minimize loss they needs a decision rule regarding who to give approval of the loan and who not to. German Credit Classification dataset obtained from the UCI(University of California,Irvine)Machine Learning Repository, was used in this study. The number of examples in this dataset is sufficient and its values for each attribute are complete or available.\par
The number of examples in the dataset is 1000.The dataset is classified into two classes:good and bad class. The good class has 700 examples whereas the bad one has 300. The dataset has 20 attributes, Seven of the attributes are of continuous(numerical) types, while the other 13 are of categorical types. The summary of data is given below:\\

<<>>=
data<-read.csv("/home/freestyler/BDA_project/Data/german.csv")
summary(data)
@

The data may not be tidy and we may have to preprocess the data before our analysis can be done. We will discuss how we prepared the data in the following section.\\

\subsection{Preparing data} 
\hspace{0.5cm}After examine the whole data,it is found that there is no missing values for all attributes. The next step in this study is the statistical analysis of the data.
%You invested lot of times preparing your data for exploration. Why not you describe what you did and how you did. You may add your R codes so that others know what exactly you did. For example let us view the summary of the data as below.
%Try to avoid putting raw output like this in your final report. Instead make a clean table as shown in table \ref{summary-data}. If you have to keep some raw output of your analysis please put them in a section called appendix at the end of the document. If you really believe that you have to put them here, you can do that and thats why we have this example here.

%\subsection{What is funny} This section may not be necessary. But if you notice something  about the data that does not make any sense you can mention them in a section like that. Or if you think of anything interesting about the data, just discuss them here.

\section{Methodology} This section will include the methods you are planning to use for your analysis. You should include some theoretical justification here. For example, why you think the method is applicable, what are the assumptions about the methods, whether your data satisfies those assumption or not etc. 

\subsection{The model}
These theories may require you to type mathematical equations and we need to refer them in the text like equation \ref{eq:reg}.

\begin{equation} \label{eq:reg}
 Y = \beta_0 + \beta_1 X + \epsilon
\end{equation}
where $\epsilon \sim N(0,1)$.

You should discuss the exploratory steps and the logical conclusion of adopting equation \ref{eq:reg} for fitting to your data. Clearly mention the conditions and the assumptions of the model. Do not write any result of the model in this section. This section is only for theoretical discussion and any results of these models should be discussed in results section.

\subsection{Data product} You may end up building a data product in your project. You may discuss about the plan here.

\section{Result and Discussions} In result section you can start with an overview of what you have found during the exploration of data. 

\subsection{Including tables}
Include some summary tables of the data as as shown in table \ref{summary-data}. Make sure you discuss about the table you have included and explain the facts it is revealing. You have to sell your table in a way that the reader will understand that this table was awesome and it reveals a fact the reader would otherwise not recognize.\\

Notice that we used the function \texttt{xtable()} form the \textbf{R} package \texttt{xtable} \cite{xtab} to generate a pretty table. \texttt{knitr} does this using \LaTeX{} codes generated by \texttt{xtable} and automatically put it in a nicer we and we don't have to worry about its position. Also notice how we write the caption of the table as well as refer the table \ref{summary-data} from the text.

<<summary-data, tidy=TRUE, results ='asis'>>=
# Creating and printing summary data table
library(xtable)
summary_data <- apply(trees,2,function(x){return(c(Average=mean(x), Median=median(x), SD =sd(x), Range =range(x)))})
print(
  xtable(summary_data,digits=2,
       caption =paste("This table caption really", "describes what this table is about and what interesting facts it is revealing."), label = 'summary-data'), 
  caption.placement = getOption("xtable.caption.placement", "top")
  )
@

\subsubsection{Book quality table} We can add tables that look like the tables in the book. For this we need to add package \texttt{booktabs} in the preamble of this .Rnw file. This will include a package called \texttt{booktabs} onto \LaTeX. Once we add that we can now put option \texttt{booktabs = TRUE} in the \textbf{R} code as below.

<<eval=TRUE,  results='asis'>>=
library(knitr)
x <- head(mtcars)
kable(x,format = 'latex', booktabs = TRUE)
@

\subsection{Including figures} Please don't forget to add nice data plots in your documents. Plots are nice to conveying message and much better than tables. Discuss what facts the figure is revealing and refer the figure from the text as figure \ref{fig:data-plot}.

<<data-plot, fig.width=5, fig.height=5, fig.align='center', fig.cap="Awesome figure caption" ,out.width='.6\\\\linewidth',fig.pos="hbtp">>=
plot(trees)
@

\subsection{How the data product works} If you build a data product you may discuss here how it works and what it provides. For data product being your main purpose, your main section may be different from just saying \texttt{Results}. You may think how you rename your sections to naturally fit in your work and the purpose.

\section{Conclusion} The conclusion is an elaboration of your abstract. Here you will discuss what you have done and how. The gist of the results need to be mentioned here. It needs to be convincing and the reader will never regret forgetting the date. Please keep it in mind that there may be readers who only read your conclusion. So, make your conclusion complete so that no reader misses anything even if they don't want to read the whole document.\\

Each paragraph of the conclusion may discuss one result you have found or one concept you are proposing. Discuss your findings and why it is better and how it is compared to any existing methods may exist. \\

Please don't forget to cite the works of others if you used it in your analysis. The citation is important for two reasons. Fist of all it acknowledges the good works other people have done which encourages them keep continue doing their good work. Second, it protects you from plagiarism which is a very nasty task everyone should avoid.\\

There should be one paragraph about the future direction of the work you have done. You would like to make it so fascinating that the reader would wish to be involved in this work in future. \\

Finally this is just a template. Your exact document may have a very different outlook. It demonstrates how you can start to write a document. Our biggest problem is to figure out where to start from. And this documents provides a guide for that. I hope it turns out to be helpful for some of the readers. If you have any comments or concern about this document please let me know so that I can improve this document. 


\section{References}
\begin{thebibliography}{9}

\bibitem{xtab}
    David B. Dahl,
    \emph{xtable: Export tables to LaTeX or HTML},
    R package version 1.7-3,
    http://CRAN.R-project.org/package=xtable, 
    2014

\bibitem{lamport94}
  Leslie Lamport, \emph{\LaTeX: A Document Preparation System}.
  Addison Wesley, Massachusetts,
  2nd Edition, 1994.

\bibitem{R-base}
  R Core Team, \emph{R: A Language and Environment for Statistical Computing},
  R Foundation for Statistical Computing,
  Vienna, Austria, http://www.R-project.org/ ,
  2014
  
\bibitem{R-knitr}
  Yihui Xie
  \emph{knitr: A general-purpose package for dynamic report generation in R},
  http://yihui.name/knitr/, 2014  

\end{thebibliography}

\end{document}
